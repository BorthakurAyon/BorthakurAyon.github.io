@incollection{conference_1,
author = {A. Borthakur},
  title = {What can we learn about the sense of smell through Neuromorphic AI?},
  note = {SKC Science & Technology Webinar, Host: Prof. Deep Medhi, Program Director, NSF, USA},
  year = {2021},
}

@incollection{conference_2,
author = {A. Borthakur},
  title = {Sparse event-based spatio-temporal oscillator for learning in the wild.},
  note = {CS Seminar, Lawrence Berkeley National Laboratory, Berkeley, CA, USA},
  year = {2021},
}

@incollection{conference_3,
author = {A. Borthakur},
  title = {Lifelong learning in the wild using Intel Loihi.},
  note = {From Neuroscience to Artificially Intelligent Systems (NAISys), Cold Spring Harbor, NY, USA},
  year = {2020},
}

@incollection{conference_4,
author = {A. Borthakur},
  title = {Signal Conditioning for learning in the wild.},
  note = {7th Annual Neuro-Inspired Computational Elements Workshop, Albany, NY, USA},
  year = {2019},
}





@patent{cu_patent,
    Author = {T. A. Cleland and N. Imam and A. Borthakur},
    Title = {Neuromorphic algorithm for rapid online learning and signal restoration.},
    Year = {2022},
    school = {Cornell University},
    Note = {US Patent App. 17/603,171},
    file = {US20220198245A1.pdf},
}

@patent{inn2_patent,
    Author = {S. Paul and and A. Borthakur},
    Title = {Sequential Neural Machine: a memory optimal solution for ultra low power and high speed inference.},
    Year = {2022},
}

@patent{inn1_patent,
    Author = {Kozdon, K and Maksimiuk, D and Borthakur, A and Bogdan, PA. },
    Title = {Method for efficient Radar pre-processing.},
    Year = {2022},
}



@thesis{ayon_thesis,
    Author = {A. Borthakur},
    Title = {Mechanisms and architectural priors for learning in the wild.},
    Year = {2021},
    school = {Cornell University},
    Note = {Ph.D. Thesis},
}

@article{Borthakur22,
    doi = {10.48550/arXiv.2204.06216},
    title = {Sapinet: A sparse event-based spatiotemporal oscillator for learning in the wild},
    year = {2022},
    Author = {A. Borthakur},
    journal = {arXiv},
    file = {2204.06216v1.pdf},
    abstract = {We introduce Sapinet -- a spike timing (event)-based multilayer neural network for \textit{learning in the wild} -- that is: one-shot online learning of multiple inputs without catastrophic forgetting, and without the need for data-specific hyperparameter retuning. Key features of Sapinet include data regularization, model scaling, data classification, and denoising. The model also supports stimulus similarity mapping. We propose a systematic method to tune the network for performance. We studied the model performance on different levels of odor similarity, gaussian and impulse noise. Sapinet achieved high classification accuracies on standard machine olfaction datasets without the requirement of fine tuning for a specific dataset.}}

@article{Borthakur20,
    doi = {10.3389/fncom.2020.579143},
    title = {A Systematic Framework for Olfactory Bulb Signal Transformations},
    year = {2020},
    volume = {14:579143},
    Author = {T.A. Cleland and A. Borthakur},
    journal = {Frontiers in Computational Neuroscience},
    file = {fncom-14-579143.pdf},
    abstract = {We describe an integrated theory of olfactory systems operation that incorporates experimental findings across scales, stages, and methods of analysis into a common framework. In particular, we consider the multiple stages of olfactory signal processing as a collective system, in which each stage samples selectively from its antecedents. We propose that, following the signal conditioning operations of the nasal epithelium and glomerular-layer circuitry, the plastic external plexiform layer of the olfactory bulb effects a process of category learningâ€”the basis for extracting meaningful, quasi-discrete odor representations from the metric space of undifferentiated olfactory quality. Moreover, this early categorization process also resolves the foundational problem of how odors of interest can be recognized in the presence of strong competitive interference from simultaneously encountered background odorants. This problem is fundamentally constraining on early-stage olfactory encoding strategies and must be resolved if these strategies and their underlying mechanisms are to be understood. Multiscale general theories of olfactory systems operation are essential in order to leverage the analytical advantages of engineered approaches together with our expanding capacity to interrogate biological systems.}}

@inproceedings{Borthakur19B,
    Author = {A.Borthakur and T.A. Cleland},
    Year = {2019},
    Title = {Signal Conditioning for Learning in the Wild},
    Booktitle = {NICE '19: Proceedings of the 7th Annual Neuro-inspired Computational Elements Workshop},
    Address = {Albany, USA},
    file = {1907.05827.pdf},
}

@article{Borthakur19A,
    doi = {10.3389/fnins.2019.00656},
    title = {A Spike Time-Dependent Online Learning Algorithm Derived From Biological Olfaction},
    year = {2019},
    volume = {13:656},
    Author = {A.Borthakur and T.A. Cleland},
    journal = {Frontiers in Neuromorphic Engineering},
    file = {fnins-13-00656.pdf},
    abstract = {We have developed a spiking neural network (SNN) algorithm for signal restoration and identification based on principles extracted from the mammalian olfactory system and broadly applicable to input from arbitrary sensor arrays. For interpretability and development purposes, we here examine the properties of its initial feedforward projection. Like the full algorithm, this feedforward component is fully spike timing-based, and utilizes online learning based on local synaptic rules such as spike timing-dependent plasticity (STDP). Using an intermediate metric to assess the properties of this initial projection, the feedforward network exhibits high classification performance after few-shot learning without catastrophic forgetting, and includes a none of the above outcome to reflect classifier confidence. We demonstrate online learning performance using a publicly available machine olfaction dataset with challenges including relatively small training sets, variable stimulus concentrations, and 3 years of sensor drift.
}}

@inproceedings{Borthakur17,
    Author = {A.Borthakur and T.A. Cleland},
    Year = {2017},
    Title = {A Neuromorphic Transfer Learning Algorithm for Orthogonalizing Highly Overlapping Sensor Array Responses},
    Booktitle = {IEEE: International Symposium on Olfaction and Electronic Nose (ISOEN)},
    Address = {Montreal, Canada},
    file = {2017_ISOEN, Borthakur.pdf},
}

@article{Borthakur16,
    doi = {10.1162/NECO_a_00827},
    title = {Effect of Reference Scheme on Power and Phase of the Local Field Potential},
    year = {2016},
    volume = {28},
    Author = {V. Shirhatti and A. Borthakur and S. Ray},
    journal = {Neural Computation},
    file = {neco_a_00827.pdf},
    abstract = {Brain signals are often analyzed in the spectral domain, where the power spectral density (PSD) and phase differences and consistency can reveal important information about the network. However, for proper interpretation, it is important to know whether these measures depend on stimulus/behavioral conditions or the reference scheme used to analyze data. We recorded local field potential (LFP) from an array of microelectrodes chronically implanted in area V1 of monkeys under different stimulus/behavioral conditions and computed PSD slopes, coherence, and phase difference between LFPs as a function of frequency and interelectrode distance while using four reference schemes: single wire, average, bipolar, and current source density. PSD slopes were dependent on reference scheme at low frequencies (below 200 Hz) but became invariant at higher frequencies. Average phase differences between sites also depended critically on referencing, switching from 0 degrees for single-wire to 180 degrees for average reference. Results were consistent across different stimulus/behavioral conditions. We were able to account for these results based on the coherence profile across sites and properties of the spectral estimator. Our results show that using different reference schemes can have drastic effects on phase differences and PSD slopes and therefore must be interpreted carefully to gain insights about network properties.}
}


